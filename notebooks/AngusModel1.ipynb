{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "magnetic-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "falling-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train_data = pd.read_csv(r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\NBA Kaggle\\adsi_g5_kaggle_nba\\data\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\NBA Kaggle\\adsi_g5_kaggle_nba\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handled-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust data\n",
    "train_data_x = train_data.copy()\n",
    "train_data_x = train_data_x.drop(['Id_old', 'Id'], axis=1)\n",
    "train_data_target = train_data_x.pop('TARGET_5Yrs')\n",
    "test_data_x = test_data.drop(['Id_old', 'Id'], axis=1)\n",
    "\n",
    "# MinMax Adjust data\n",
    "scaler = MinMaxScaler()\n",
    "df_train_scaled = pd.DataFrame(scaler.fit_transform(train_data_x), columns=train_data_x.columns)\n",
    "\n",
    "# train test val splits\n",
    "X_data, X_test, y_data, y_test = train_test_split(df_train_scaled, train_data_target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addressed-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Set XGBoost model\n",
    "# Source: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "trained-bibliography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6760843613211301"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model ROC\n",
    "roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollywood-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "\n",
    "\"\"\"\"learning_rate\", [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ),\n",
    "            (\"max_depth\"    , [  3 , 4 , 5, 6,  8, 10, 12, 15 ] ),\n",
    "            (\"min_child_weight\", [ 1, 3, 5, 7 ] ),\n",
    "            (\"gamma\", [0.0, 0.1, 0.2, 0.3, 0.4 ]),\n",
    "            (\"colsample_bytree\", [  0.3, 0.4, 0.5, 0.7 ] )\n",
    "            \n",
    "n_est = [int(x) for x in np.linspace(start=200, stop=2000, num=50)]\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num=1)]\n",
    "min_samples_split = [2,5,10]\n",
    "bootstrap = [True, False]\n",
    "class_weight = [None, 'balanced']\"\"\"\n",
    "\n",
    "random_grid = {'learning_rate':[0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "              'max_depth': [3, 4 , 5, 6,  8, 10, 12, 15],\n",
    "              'min_child_weight': [1, 3, 5, 7],\n",
    "               'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "              'colsample_bytree': [ 0.3, 0.4, 0.5, 0.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "looking-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\angus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:03:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation the tune model\n",
    "clf = XGBClassifier()\n",
    "xgb_rcv = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "xgb_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-intersection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7074934478642095"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model ROC\n",
    "roc_auc_score(y_val, xgb_rcv.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "temporal-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check against test set\n",
    "y_pred = xgb_rcv.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "designing-practice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  TARGET_5Yrs\n",
       "0   0            1\n",
       "1   1            1\n",
       "2   2            1\n",
       "3   3            1\n",
       "4   4            1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission output\n",
    "preddf = pd.DataFrame(y_pred, columns=['TARGET_5Yrs'])\n",
    "submit = pd.DataFrame(test_data['Id']).merge(preddf, right_index=True, left_index=True, how='left')\n",
    "\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "signal-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out\n",
    "submit.to_csv(r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\NBA Kaggle\\ANSubmit1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-flexibility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
