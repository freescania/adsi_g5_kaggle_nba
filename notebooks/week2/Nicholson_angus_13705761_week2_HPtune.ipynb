{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "miniature-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "# Package Imports\n",
    "\n",
    "# File management\n",
    "import os\n",
    "\n",
    "# Data/numeric manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelling & Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe,hp,Trials\n",
    "from hyperopt.fmin import fmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metallic-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data\n",
    "\n",
    "# Read in data\n",
    "train_data = pd.read_csv(r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\NBA Kaggle\\adsi_g5_kaggle_nba\\data\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\Angus\\Documents\\UTS MDSI\\Advanced DSI\\NBA Kaggle\\adsi_g5_kaggle_nba\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brown-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust data\n",
    "train_data_x = train_data.copy()\n",
    "train_data_x = train_data_x.drop(['Id_old', 'Id'], axis=1)\n",
    "train_data_target = train_data_x.pop('TARGET_5Yrs')\n",
    "test_data_x = test_data.drop(['Id_old', 'Id'], axis=1)\n",
    "\n",
    "# Don't MinMax Adjust data\n",
    "\"\"\"scaler = StandardScaler()\n",
    "df_train_scaled = pd.DataFrame(scaler.fit_transform(train_data_x), columns=train_data_x.columns)\n",
    "df_test_data_scaled = pd.DataFrame(scaler.fit_transform(test_data_x), columns=test_data_x.columns)\"\"\"\n",
    "\n",
    "# train test val splits\n",
    "X_data, X_test, y_data, y_test = train_test_split(train_data_x.to_numpy(), train_data_target.to_numpy(), test_size=0.2, random_state=42) # to numpy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organized-indication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.58s/trial, best loss: 0.2666015625]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  4.10s/trial, best loss: 0.2666015625]\n",
      "100%|████████████████████████████████████████████████████████| 3/3 [00:33<00:00, 33.69s/trial, best loss: 0.2666015625]\n",
      "100%|████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  3.89s/trial, best loss: 0.2666015625]\n",
      "100%|█████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  6.84s/trial, best loss: 0.189453125]\n",
      "100%|█████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  4.61s/trial, best loss: 0.189453125]\n",
      "100%|█████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  4.10s/trial, best loss: 0.189453125]\n",
      "100%|█████████████████████████████████████████████████████████| 8/8 [00:17<00:00, 17.00s/trial, best loss: 0.189453125]\n",
      "100%|█████████████████████████████████████████████████████████| 9/9 [00:04<00:00,  4.12s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 10/10 [00:04<00:00,  4.02s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 11/11 [00:08<00:00,  8.98s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 12/12 [00:04<00:00,  4.21s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 13/13 [00:04<00:00,  4.63s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 14/14 [00:04<00:00,  4.13s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 15/15 [00:04<00:00,  4.04s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 16/16 [00:04<00:00,  4.18s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 17/17 [00:03<00:00,  3.80s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 18/18 [00:06<00:00,  6.11s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 19/19 [00:05<00:00,  5.83s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.47s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 21/21 [00:08<00:00,  8.31s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 22/22 [00:04<00:00,  4.25s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 23/23 [00:04<00:00,  4.31s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 24/24 [00:33<00:00, 33.88s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 25/25 [00:04<00:00,  4.09s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 26/26 [00:04<00:00,  4.04s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 27/27 [00:07<00:00,  7.00s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 28/28 [00:03<00:00,  3.98s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 29/29 [00:04<00:00,  4.22s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 30/30 [00:04<00:00,  4.20s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 31/31 [00:04<00:00,  4.16s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 32/32 [00:07<00:00,  7.36s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 33/33 [00:09<00:00,  9.21s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 34/34 [00:03<00:00,  3.95s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 35/35 [00:03<00:00,  3.98s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 36/36 [00:11<00:00, 11.45s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 37/37 [00:04<00:00,  4.02s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 38/38 [00:10<00:00, 10.07s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 39/39 [00:07<00:00,  7.21s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 40/40 [00:04<00:00,  4.27s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 41/41 [00:09<00:00,  9.29s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 42/42 [00:05<00:00,  5.15s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 43/43 [00:08<00:00,  8.47s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 44/44 [00:04<00:00,  4.40s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 45/45 [00:33<00:00, 33.85s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 46/46 [00:04<00:00,  4.90s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 47/47 [00:10<00:00, 10.50s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 48/48 [00:16<00:00, 16.57s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 49/49 [00:13<00:00, 13.97s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 50/50 [00:10<00:00, 10.01s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 51/51 [00:22<00:00, 22.48s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 52/52 [00:04<00:00,  4.38s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 53/53 [00:04<00:00,  4.50s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 54/54 [00:04<00:00,  4.43s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 55/55 [00:04<00:00,  4.49s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 56/56 [00:04<00:00,  4.58s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 57/57 [00:04<00:00,  4.14s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 58/58 [00:04<00:00,  4.32s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 59/59 [00:04<00:00,  4.13s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 60/60 [00:13<00:00, 13.67s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 61/61 [00:06<00:00,  6.98s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 62/62 [00:04<00:00,  4.24s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 63/63 [00:06<00:00,  6.70s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 64/64 [00:06<00:00,  6.09s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 65/65 [00:08<00:00,  8.80s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 66/66 [00:04<00:00,  4.16s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 67/67 [00:04<00:00,  4.52s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 68/68 [00:07<00:00,  7.55s/trial, best loss: 0.189453125]\n",
      "100%|███████████████████████████████████████████████████████| 69/69 [00:04<00:00,  4.04s/trial, best loss: 0.189453125]\n",
      "100%|██████████████████████████████████████████████████████| 70/70 [00:04<00:00,  4.43s/trial, best loss: 0.1884765625]\n",
      "100%|██████████████████████████████████████████████████████| 71/71 [00:04<00:00,  4.62s/trial, best loss: 0.1884765625]\n",
      "100%|██████████████████████████████████████████████████████| 72/72 [00:04<00:00,  4.17s/trial, best loss: 0.1884765625]\n",
      "100%|██████████████████████████████████████████████████████| 73/73 [00:04<00:00,  4.37s/trial, best loss: 0.1884765625]\n",
      "100%|██████████████████████████████████████████████████████| 74/74 [00:04<00:00,  4.34s/trial, best loss: 0.1884765625]\n",
      "100%|████████████████████████████████████████████████████████████| 75/75 [00:04<00:00,  4.28s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 76/76 [00:04<00:00,  4.57s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 77/77 [00:04<00:00,  4.29s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 78/78 [00:33<00:00, 33.97s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 79/79 [00:04<00:00,  4.24s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 80/80 [00:04<00:00,  4.22s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 81/81 [00:04<00:00,  4.23s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 82/82 [00:06<00:00,  6.39s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 83/83 [00:04<00:00,  4.12s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 84/84 [00:06<00:00,  6.36s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 85/85 [00:07<00:00,  7.01s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 86/86 [00:04<00:00,  4.59s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 87/87 [00:05<00:00,  5.32s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 88/88 [00:04<00:00,  4.72s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 89/89 [00:04<00:00,  4.62s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 90/90 [00:04<00:00,  4.46s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 91/91 [00:04<00:00,  4.53s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 92/92 [00:23<00:00, 23.85s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 93/93 [00:08<00:00,  8.21s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 94/94 [00:05<00:00,  5.93s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 95/95 [00:05<00:00,  5.59s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 96/96 [00:34<00:00, 34.25s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 97/97 [00:08<00:00,  8.91s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 98/98 [00:07<00:00,  7.77s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████████████| 99/99 [00:04<00:00,  4.58s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 100/100 [00:07<00:00,  7.51s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 101/101 [00:11<00:00, 11.83s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 102/102 [00:04<00:00,  4.60s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 103/103 [00:04<00:00,  4.25s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 104/104 [00:04<00:00,  4.28s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 105/105 [00:04<00:00,  4.98s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 106/106 [00:04<00:00,  4.62s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 107/107 [00:04<00:00,  4.30s/trial, best loss: 0.1875]\n",
      "100%|██████████████████████████████████████████████████████████| 108/108 [00:33<00:00, 33.98s/trial, best loss: 0.1875]\n",
      "100%|████████████████████████████████████████████████████| 109/109 [00:06<00:00,  6.14s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 110/110 [00:04<00:00,  4.59s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 111/111 [00:04<00:00,  4.31s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 112/112 [00:04<00:00,  4.09s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 113/113 [00:04<00:00,  4.19s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 114/114 [00:04<00:00,  4.16s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 115/115 [00:04<00:00,  4.40s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 116/116 [00:04<00:00,  4.44s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 117/117 [00:04<00:00,  4.20s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 118/118 [00:05<00:00,  5.43s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 119/119 [00:05<00:00,  5.43s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 120/120 [00:05<00:00,  5.91s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 121/121 [00:06<00:00,  6.05s/trial, best loss: 0.1865234375]\n",
      "100%|████████████████████████████████████████████████████| 122/122 [00:05<00:00,  5.61s/trial, best loss: 0.1865234375]\n",
      "100%|█████████████████████████████████████████████████████| 123/123 [00:06<00:00,  6.31s/trial, best loss: 0.185546875]\n",
      "100%|█████████████████████████████████████████████████████| 124/124 [00:05<00:00,  5.17s/trial, best loss: 0.185546875]\n",
      "100%|█████████████████████████████████████████████████████| 125/125 [00:05<00:00,  5.31s/trial, best loss: 0.185546875]\n",
      "100%|█████████████████████████████████████████████████████| 126/126 [00:04<00:00,  4.47s/trial, best loss: 0.185546875]\n",
      "100%|████████████████████████████████████████████████████| 127/127 [00:07<00:00,  7.79s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 128/128 [00:05<00:00,  5.16s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 129/129 [00:10<00:00, 10.48s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 130/130 [00:04<00:00,  4.82s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 131/131 [00:05<00:00,  5.82s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 132/132 [00:05<00:00,  5.48s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 133/133 [00:04<00:00,  4.17s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 134/134 [00:05<00:00,  5.25s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 135/135 [00:07<00:00,  7.87s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 136/136 [00:20<00:00, 20.84s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 137/137 [00:05<00:00,  5.91s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 138/138 [00:10<00:00, 10.81s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 139/139 [00:10<00:00, 10.98s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 140/140 [00:18<00:00, 18.92s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 141/141 [00:33<00:00, 33.98s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 142/142 [00:04<00:00,  4.42s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 143/143 [00:17<00:00, 17.21s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 144/144 [00:10<00:00, 10.91s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 145/145 [00:33<00:00, 33.92s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 146/146 [00:05<00:00,  5.59s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 147/147 [00:07<00:00,  8.00s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 148/148 [00:04<00:00,  4.60s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 149/149 [00:05<00:00,  5.26s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 150/150 [00:21<00:00, 21.92s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 151/151 [00:07<00:00,  7.19s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 152/152 [00:08<00:00,  8.17s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 153/153 [00:34<00:00, 34.09s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 154/154 [00:33<00:00, 33.88s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 155/155 [00:04<00:00,  4.88s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 156/156 [00:04<00:00,  4.17s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 157/157 [00:24<00:00, 24.50s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 158/158 [00:04<00:00,  4.39s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 159/159 [00:05<00:00,  5.59s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 160/160 [00:04<00:00,  4.41s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 161/161 [00:10<00:00, 10.71s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 162/162 [00:13<00:00, 13.99s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 163/163 [00:04<00:00,  4.58s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 164/164 [00:07<00:00,  7.88s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 165/165 [00:05<00:00,  5.18s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 166/166 [00:07<00:00,  7.42s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 167/167 [00:04<00:00,  4.95s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 168/168 [00:04<00:00,  4.95s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 169/169 [00:09<00:00,  9.20s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 170/170 [00:26<00:00, 26.35s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 171/171 [00:32<00:00, 32.13s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 172/172 [00:27<00:00, 27.72s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 173/173 [00:34<00:00, 34.06s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 174/174 [00:26<00:00, 26.64s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 175/175 [00:04<00:00,  4.31s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 176/176 [00:25<00:00, 25.07s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 177/177 [00:05<00:00,  5.23s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 178/178 [00:04<00:00,  4.68s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 179/179 [00:04<00:00,  4.28s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 180/180 [00:14<00:00, 14.45s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 181/181 [00:24<00:00, 24.33s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 182/182 [00:31<00:00, 31.97s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 183/183 [00:11<00:00, 11.32s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 184/184 [00:11<00:00, 11.13s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 185/185 [00:10<00:00, 10.88s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 186/186 [00:05<00:00,  5.28s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 187/187 [00:04<00:00,  4.25s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 188/188 [00:05<00:00,  5.02s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 189/189 [00:04<00:00,  4.58s/trial, best loss: 0.1845703125]\n",
      "100%|████████████████████████████████████████████████████| 190/190 [00:34<00:00, 34.02s/trial, best loss: 0.1845703125]\n",
      "Accuracy: 0.845\n",
      "{'learner': RandomForestClassifier(max_features=0.7640161111447819, n_estimators=124,\n",
      "                       n_jobs=1, random_state=4, verbose=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "### Hyperopt sklearn HP tuning\n",
    "# Source: https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/\n",
    "\n",
    "# define search\n",
    "model = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, max_evals=190, trial_timeout=30)\n",
    "# evals = 190\n",
    "# perform the search\n",
    "model.fit(X_train, y_train) #Change to lower evals\n",
    "# summarize performance\n",
    "acc = model.score(X_val, y_val)\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "critical-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 500/500 [1:10:35<00:00,  8.47s/trial, best loss: 0.1205177548455046]\n"
     ]
    }
   ],
   "source": [
    "### HP Tuning Random Forest Classifier with Hyperopt\n",
    "# Source: https://www.kaggle.com/virajbagal/eda-xgb-random-forest-parameter-tuning-hyperopt\n",
    "\n",
    "seed=2\n",
    "def objective(params):\n",
    "    est=int(params['n_estimators'])\n",
    "    md=int(params['max_depth'])\n",
    "    msl=int(params['min_samples_leaf'])\n",
    "    mss=int(params['min_samples_split'])\n",
    "    model=RandomForestRegressor(n_estimators=est,max_depth=md,min_samples_leaf=msl,min_samples_split=mss)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_val)\n",
    "    score=mean_squared_error(y_val,pred)\n",
    "    return score\n",
    "\n",
    "def optimize(trial):\n",
    "    params={'n_estimators':hp.uniform('n_estimators',100,500),\n",
    "           'max_depth':hp.uniform('max_depth',5,20),\n",
    "           'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "           'min_samples_split':hp.uniform('min_samples_split',2,6)}\n",
    "    best=fmin(fn=objective,space=params,algo=tpe.suggest,trials=trial,max_evals=50,rstate=np.random.RandomState(seed)) #max_evals=500\n",
    "    return best\n",
    "\n",
    "trial=Trials()\n",
    "#best=optimize(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acceptable-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8.857333102037256, 'min_samples_leaf': 1.2584108003917138, 'min_samples_split': 5.263031441354376, 'n_estimators': 257.42270665919244}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "academic-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 0.1208891230945162, 'status': 'ok'}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'max_depth': [0], 'min_samples_leaf': [0], 'min_samples_split': [0], 'n_estimators': [0]}, 'vals': {'max_depth': [6.44924027262962], 'min_samples_leaf': [3.2557038491408083], 'min_samples_split': [3.705893814587132], 'n_estimators': [310.68170422696016]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2021, 2, 14, 6, 26, 8, 298000), 'refresh_time': datetime.datetime(2021, 2, 14, 6, 26, 13, 886000)}\n",
      "{'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 0.12295173308854075, 'status': 'ok'}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'max_depth': [1], 'min_samples_leaf': [1], 'min_samples_split': [1], 'n_estimators': [1]}, 'vals': {'max_depth': [13.330641077198102], 'min_samples_leaf': [4.1346696482442695], 'min_samples_split': [3.3480498788350173], 'n_estimators': [446.25537837458296]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2021, 2, 14, 6, 26, 13, 923000), 'refresh_time': datetime.datetime(2021, 2, 14, 6, 26, 28, 50000)}\n"
     ]
    }
   ],
   "source": [
    "for t in trial.trials[:2]:\n",
    "    print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mineral-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "TID=[t['tid'] for t in trial.trials]\n",
    "Loss=[t['result']['loss'] for t in trial.trials]\n",
    "maxd=[t['misc']['vals']['max_depth'][0] for t in trial.trials]\n",
    "nest=[t['misc']['vals']['n_estimators'][0] for t in trial.trials]\n",
    "min_ss=[t['misc']['vals']['min_samples_split'][0] for t in trial.trials]\n",
    "min_sl=[t['misc']['vals']['min_samples_leaf'][0] for t in trial.trials]\n",
    "\n",
    "hyperopt_rfr=pd.DataFrame({'tid':TID,'loss':Loss,\n",
    "                          'max_depth':maxd,'n_estimators':nest,\n",
    "                          'min_samples_split':min_ss, 'min_samples_leaf':min_sl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sacred-cameroon",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d427ffc68009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt_rfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt_rfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(3,2,figsize=(10,10))\n",
    "plt.subplot(3,2,1)\n",
    "sns.scatterplot(x='tid',y='max_depth',data=hyperopt_rfr)\n",
    "plt.subplot(3,2,2)\n",
    "sns.scatterplot(x='tid',y='loss',data=hyperopt_rfr)\n",
    "plt.subplot(3,2,3)\n",
    "sns.scatterplot(x='tid',y='n_estimators',data=hyperopt_rfr)\n",
    "plt.subplot(3,2,4)\n",
    "sns.scatterplot(x='tid',y='min_samples_leaf',data=hyperopt_rfr)\n",
    "plt.subplot(3,2,5)\n",
    "sns.scatterplot(x='tid',y='min_samples_split',data=hyperopt_rfr)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-algebra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
